{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "206cd3e2-4e1e-4a5e-bf73-6a0d3cbb93fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import time\n",
    "import random\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40612a5e-8163-4a65-b69b-288257a3994a",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = gym.make(\"FrozenLake-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d3458fe-8a0a-4bb8-8b29-f7fa23049032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******Q-Table 1****** \n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "actionSpaceSize = environment.action_space.n\n",
    "stateSpaceSize = environment.observation_space.n\n",
    "\n",
    "qTable = np.zeros((stateSpaceSize, actionSpaceSize))\n",
    "print(\"******Q-Table 1******\", \"\\n\\n\", qTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3748bcd4-10d7-41ff-a861-eb0b7d327666",
   "metadata": {},
   "outputs": [],
   "source": [
    "numEpisodes = 9000\n",
    "maxStepsPerEpisode = 100\n",
    "\n",
    "learningRate = 0.1\n",
    "discountRate = 0.9\n",
    "\n",
    "explorationRate = 1\n",
    "maxExplorationRate = 1\n",
    "minExplorationRate = 0.01\n",
    "explorationDecay = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b50d7b54-55fd-4b93-a432-525056415247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******Average Reward Per 1000 Episodes******\n",
      "\n",
      "1000 :  0.04200000000000003\n",
      "2000 :  0.16200000000000012\n",
      "3000 :  0.2940000000000002\n",
      "4000 :  0.4080000000000003\n",
      "5000 :  0.4880000000000004\n",
      "6000 :  0.4210000000000003\n",
      "7000 :  0.5480000000000004\n",
      "8000 :  0.4880000000000004\n",
      "9000 :  0.5820000000000004\n",
      "\n",
      "\n",
      "******Q-Table 2******\n",
      "\n",
      "[[0.05119954 0.06090029 0.05084118 0.05018583]\n",
      " [0.02776524 0.02495063 0.02847737 0.06282199]\n",
      " [0.08781348 0.03873646 0.03887193 0.03905012]\n",
      " [0.03140255 0.02912191 0.03177502 0.03729913]\n",
      " [0.09331375 0.06512045 0.06015906 0.04289752]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.12230854 0.02765741 0.03292698 0.03376986]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.06781841 0.07054627 0.07642782 0.18109315]\n",
      " [0.11205108 0.2829448  0.13755302 0.12212449]\n",
      " [0.36177856 0.21073659 0.12097812 0.12059501]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.14325398 0.21195859 0.46438756 0.2128218 ]\n",
      " [0.35133014 0.81121226 0.36634537 0.48542562]\n",
      " [0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "rewardsAllEpisodes = []\n",
    "\n",
    "for episode in range(numEpisodes):\n",
    "    state = environment.reset()\n",
    "    \n",
    "    done = False\n",
    "    rewardsCurrentEpisode = 0\n",
    "    \n",
    "    for step in range(maxStepsPerEpisode):\n",
    "        explorationRateThreshold = random.uniform(0,1)\n",
    "        if explorationRateThreshold > explorationRate:\n",
    "            action = np.argmax(qTable[state,:])\n",
    "        else:\n",
    "            action = environment.action_space.sample()\n",
    "            \n",
    "        newState, reward,  done, info = environment.step(action)\n",
    "        \n",
    "        # Update Q-table for Q(s,a)\n",
    "        qTable[state, action] = qTable[state, action] * (1 - learningRate) + learningRate * (reward + discountRate * np.max(qTable[newState, :]))\n",
    "    \n",
    "        state = newState\n",
    "        rewardsCurrentEpisode += reward\n",
    "        \n",
    "        if done == True:\n",
    "            break\n",
    "            \n",
    "    explorationRate = minExplorationRate + (maxExplorationRate - minExplorationRate) * np.exp(-explorationDecay*episode)\n",
    "    rewardsAllEpisodes.append(rewardsCurrentEpisode)\n",
    "    \n",
    "rewardsPerThousandCounts = np.split(np.array(rewardsAllEpisodes),numEpisodes/1000)\n",
    "count = 1000\n",
    "print(\"******Average Reward Per 1000 Episodes******\\n\")\n",
    "for r in rewardsPerThousandCounts:\n",
    "    print(count, \": \", str(sum(r/1000)))\n",
    "    count += 1000\n",
    "    \n",
    "print(\"\\n\\n******Q-Table 2******\\n\")\n",
    "print(qTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49d0a1d3-2d10-4bc0-9800-ebb5b96c74f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Left)\n",
      "SFFF\n",
      "F\u001b[41mH\u001b[0mFH\n",
      "FFFH\n",
      "HFFG\n",
      "*****YOU FELL INTO THE HOLE*****\n"
     ]
    }
   ],
   "source": [
    "for episode in range(5):\n",
    "    state = environment.reset()\n",
    "    done = False\n",
    "    print(\"*****EPISODE\", episode+1, \"*****\\n\\n\\n\\n\")\n",
    "    time.sleep(1)\n",
    "    \n",
    "    for step in range(maxStepsPerEpisode):\n",
    "        clear_output(wait=True)\n",
    "        environment.render()\n",
    "        time.sleep(0.3)\n",
    "        \n",
    "        action = np.argmax(qTable[state, :])\n",
    "        newState, reward, done, info = environment.step(action)\n",
    "        \n",
    "        if done:\n",
    "            clear_output(wait=True)\n",
    "            environment.render()\n",
    "            if reward == 1:\n",
    "                print(\"*****YOU REACHED THE GOAL*****\")\n",
    "                time.sleep(3)\n",
    "            else:\n",
    "                print(\"*****YOU FELL INTO THE HOLE*****\")\n",
    "                time.sleep(3)\n",
    "            clear_output(wait=True)\n",
    "            break\n",
    "            \n",
    "        state = newState\n",
    "        \n",
    "environment.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfabc94-4bb7-4e17-8941-1e075a9fbcbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45af71fd-9924-4d7b-ac56-aafe1cd80f27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bbd654-b5a9-4ccf-a6a9-f8d2e384c165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
